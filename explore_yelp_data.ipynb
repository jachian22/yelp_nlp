{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simplejson as sj\n",
    "from nltk.collocations import *\n",
    "from collections import defaultdict\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(1738)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import set_sent_model\n",
    "reload(set_sent_model)\n",
    "from set_sent_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import the data and split it into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_path = 'yds/yelp_academic_dataset_review.json'\n",
    "original_data = get_data(d_path)\n",
    "train, test = train_test_split(original_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create word features (vocabulary)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_data = [doc for doc in train if doc['stars'] == 5]\n",
    "n_data = [doc for doc in train if doc['stars'] == 1]\n",
    "\n",
    "filtered = []\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "punct = string.punctuation\n",
    "\n",
    "filtered.extend(stop_words)\n",
    "filtered.extend(punct)\n",
    "filtered.extend([\"...\", \"''\", \"``\"])\n",
    "\n",
    "for doc in p_data:\n",
    "    text = doc['text'].lower().encode('ascii', 'ignore')\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w not in filtered]\n",
    "    doc['words'] = words\n",
    "\n",
    "for doc in n_data:\n",
    "    text = doc['text'].lower().encode('ascii', 'ignore')\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w not in filtered]\n",
    "    doc['words'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "[all_words.append(w) for doc in p_data for w in doc['words']]\n",
    "[all_words.append(w) for doc in n_data for w in doc['words']]\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "all_words = all_words.most_common(5000)\n",
    "\n",
    "word_features = [tup[0] for tup in all_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('algos/word_features.pickle', 'wb') as f:\n",
    "    pickle.dump(word_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create feature matrix from word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_path = 'yds/yelp_academic_dataset_review.json'\n",
    "original_data = get_data(d_path)\n",
    "train, test = train_test_split(original_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadf = pd.DataFrame(train)\n",
    "X = datadf[datadf.stars != 3]\n",
    "y = X.apply(lambda x: 1 if x.stars > 3 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('algos/word_features.pickle', 'rb') as f:\n",
    "    word_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for w in word_features[:400]: #6ish hours\n",
    "    X[w] = X.apply(lambda x: 1 if w in x.text else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X.drop(['categories', 'review_id', 'date', 'business_id', 'text', 'type', 'user_id', 'votes', 'stars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.DataFrame(test)\n",
    "X_test = testdf[testdf.stars != 3]\n",
    "y_test = X_test.apply(lambda x: 1 if x.stars > 3 else 0, axis=1)\n",
    "for w in word_features[:400]:\n",
    "    X_test[w] = X_test.apply(lambda x: 1 if w in x.text else 0, axis=1)\n",
    "X_test.drop(['categories', 'review_id', 'date', 'business_id', 'text', 'type', 'user_id', 'votes', 'stars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_path = 'yds/yelp_academic_dataset_review.json'\n",
    "original_data = get_data(d_path)\n",
    "train, test = train_test_split(original_data, test_size=0.3)\n",
    "with open('algos/word_features.pickle', 'rb') as f:\n",
    "    word_features = pickle.load(f)\n",
    "X, y, X_test, y_test = create_feature_matrix(train, test, word_features[:400], mapped=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary sentiment prediction model using random word features from the top 5000 most frequently used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85594729273801318"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('algos/RandomForestClassifier.pickle', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important features from preliminary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_100 = np.argsort(rf.feature_importances_)[-1:-101:-1]\n",
    "X_test.columns[top_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88914426382310885"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('algos/LogRegressionClassifier.pickle', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_100 = np.argsort(lr.coef_[0])[-1:-101:-1]\n",
    "X_test.columns[top_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(lr.coef_[0])[-1:-101:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Exploratory Analysis of Combinations and Markhov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Number\n",
    "Tag\n",
    "Description\n",
    "1.\tCC\tCoordinating conjunction\n",
    "2.\tCD\tCardinal number\n",
    "3.\tDT\tDeterminer\n",
    "4.\tEX\tExistential there\n",
    "5.\tFW\tForeign word\n",
    "6.\tIN\tPreposition or subordinating conjunction\n",
    "7.\tJJ\tAdjective\n",
    "8.\tJJR\tAdjective, comparative\n",
    "9.\tJJS\tAdjective, superlative\n",
    "10.\tLS\tList item marker\n",
    "11.\tMD\tModal\n",
    "12.\tNN\tNoun, singular or mass\n",
    "13.\tNNS\tNoun, plural\n",
    "14.\tNNP\tProper noun, singular\n",
    "15.\tNNPS\tProper noun, plural\n",
    "16.\tPDT\tPredeterminer\n",
    "17.\tPOS\tPossessive ending\n",
    "18.\tPRP\tPersonal pronoun\n",
    "19.\tPRP$\tPossessive pronoun\n",
    "20.\tRB\tAdverb\n",
    "21.\tRBR\tAdverb, comparative\n",
    "22.\tRBS\tAdverb, superlative\n",
    "23.\tRP\tParticle\n",
    "24.\tSYM\tSymbol\n",
    "25.\tTO\tto\n",
    "26.\tUH\tInterjection\n",
    "27.\tVB\tVerb, base form\n",
    "28.\tVBD\tVerb, past tense\n",
    "29.\tVBG\tVerb, gerund or present participle\n",
    "30.\tVBN\tVerb, past participle\n",
    "31.\tVBP\tVerb, non-3rd person singular present\n",
    "32.\tVBZ\tVerb, 3rd person singular present\n",
    "33.\tWDT\tWh-determiner\n",
    "34.\tWP\tWh-pronoun\n",
    "35.\tWP$\tPossessive wh-pronoun\n",
    "36.\tWRB\tWh-adverb\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_path = 'yds/yelp_academic_dataset_review.json'\n",
    "w_exploration = get_data(d_path)\n",
    "train_w, test_w = train_test_split(w_exploration, test_size=0.3)\n",
    "\n",
    "train_w = [rev['text'].lower() for rev in train_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_w = [nltk.word_tokenize(rev) for rev in train_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre, post = exploratory_analysis(train_w, word_features[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print pre['wonderful']\n",
    "print post['wonderful']\n",
    "print pre['fantastic']\n",
    "print post['fantastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print pre['burger'], '\\n'\n",
    "print pre['restaurant'], '\\n'\n",
    "print pre['chicken'], '\\n'\n",
    "print post['chicken'], '\\n'\n",
    "print pre['meal'], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in [w for w in nltk.pos_tag(word_features[:400]) if 'JJ' in w[1]]:\n",
    "    print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('very', 17010), ('and', 13070), ('was', 9194), (',', 5983), ('super', 5362), ('is', 5146), ('.', 2937), ('always', 2560), ('are', 2548), ('a', 2125)]\n",
      "[('and', 28901), ('.', 17967), (',', 13242), ('staff', 6888), ('service', 5306), ('!', 1587), ('but', 1361), ('as', 791), ('people', 671), (u'&', 613)]\n"
     ]
    }
   ],
   "source": [
    "print pre['friendly']\n",
    "print post['friendly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in [w for w in nltk.pos_tag(word_features[:400]) if 'NN' in w[1]]:\n",
    "    print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('really', 'RB')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['really']) #RB RBR RBS\n",
    "# really, very, even, much, real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore mapping subjects to:\n",
    "- place\n",
    "- service\n",
    "- experience\n",
    "- prices\n",
    "- price\n",
    "- portions\n",
    "- money\n",
    "- style\n",
    "- decor\n",
    "- serve\n",
    "- cheap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 price\n",
      "158 prices\n",
      "299 money\n",
      "551 priced\n",
      "709 pricey\n",
      "942 overpriced\n",
      "\n",
      "PRICE\n",
      "[('the', 30428), ('.', 2382), ('reasonable', 2251), (u'great', 2060), ('good', 1830), ('same', 1772), ('half', 1226), ('full', 1217), ('that', 1182), ('and', 1043), ('decent', 899), ('a', 691), ('this', 620), (',', 587), ('1/2', 528), ('fair', 523), ('in', 502), ('high', 460), ('low', 456), ('affordable', 345)] \n",
      "\n",
      "PRICES\n",
      "[('the', 19213), ('.', 5359), ('reasonable', 3012), ('great', 2248), ('their', 1819), ('good', 1743), ('and', 1666), (',', 1090), ('hour', 1017), ('high', 869), ('decent', 855), ('!', 607), ('drink', 535), ('cheap', 487), ('low', 448), ('fair', 445), ('these', 393), ('affordable', 314), ('menu', 295), ('lunch', 287)] \n",
      "\n",
      "MONEY\n",
      "[('the', 4490), ('your', 3885), ('my', 2602), ('of', 2240), ('and', 790), ('our', 722), ('more', 671), ('much', 586), ('some', 556), ('for', 463), ('or', 393), ('their', 352), ('save', 338), ('less', 314), ('spend', 261), ('extra', 252), ('earned', 237), ('spending', 208), ('make', 192), ('that', 184)] \n",
      "\n",
      "PRICED\n",
      "[('reasonably', 5950), ('over', 3275), ('well', 888), ('decently', 611), ('fairly', 512), ('moderately', 408), ('and', 381), ('is', 361), ('are', 291), ('high', 284), ('half', 275), ('was', 253), ('reasonable', 188), ('.', 173), ('higher', 138), ('were', 129), ('overly', 114), (',', 112), ('1/2', 81), (\"'s\", 81)] \n",
      "\n",
      "PRICEY\n",
      "[('little', 3102), ('bit', 2890), ('the', 1077), ('is', 823), ('too', 622), ('very', 577), ('pretty', 556), ('.', 420), ('was', 419), (\"'s\", 394), ('of', 292), ('kinda', 287), ('a', 276), ('but', 268), ('quite', 240), ('are', 230), ('more', 209), ('and', 208), ('be', 201), ('tad', 181)] \n",
      "\n",
      "OVERPRICED\n",
      "[('way', 851), ('is', 803), ('and', 671), ('bit', 652), ('was', 584), ('little', 433), ('.', 428), (',', 386), ('but', 308), ('are', 284), ('the', 275), ('an', 255), ('very', 249), (\"'s\", 216), (u'slightly', 162), ('extremely', 148), ('not', 145), ('definitely', 127), ('ridiculously', 118), ('of', 105)] \n",
      "\n",
      "CHEAP\n",
      "[(u'a', 1995), ('and', 1789), (',', 1534), ('not', 1472), ('the', 1041), ('is', 952), ('.', 846), (\"'s\", 795), ('are', 759), ('for', 724), ('super', 687), ('pretty', 648), (\"n't\", 584), ('was', 562), ('very', 517), ('so', 489), ('really', 423), ('of', 344), ('dirt', 289), ('some', 276)]\n",
      "[(',', 3758), ('.', 3149), ('and', 2464), ('!', 965), ('but', 614), ('food', 530), ('for', 522), ('prices', 487), ('eats', 413), ('(', 406), ('drinks', 395), ('beer', 325), ('price', 323), ('meal', 302), ('as', 257), ('lunch', 250), ('too', 239), ('chinese', 206), ('to', 195), (')', 186)]\n"
     ]
    }
   ],
   "source": [
    "for k, w in enumerate(word_features[:1000]):\n",
    "    if 'price' in w:\n",
    "        print k, w\n",
    "    if 'money' in w:\n",
    "        print k, w\n",
    "print ''\n",
    "        \n",
    "for key in ['price', 'prices', 'money', 'priced', 'pricey', 'overpriced']:\n",
    "    print key.upper()\n",
    "    print pre[key],  '\\n'\n",
    "print 'CHEAP'\n",
    "print pre['cheap']\n",
    "print post['cheap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, w in enumerate(word_features[:1000]):\n",
    "    if 'service' in w:\n",
    "        print k, w\n",
    "    if 'serve' in w:\n",
    "        print k, w\n",
    "print ''\n",
    "\n",
    "for key in ['service', 'customer', 'server', 'served', 'serve', 'servers']:\n",
    "    print key.upper()\n",
    "    print pre[key], '\\n'\n",
    "    print post[key], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, w in enumerate(word_features[:1000]):\n",
    "    if 'decor' in w:\n",
    "        print k, w\n",
    "    if 'ambiance' in w:\n",
    "        print k, w\n",
    "    if 'atmosphere' in w:\n",
    "        print k, w\n",
    "print ''\n",
    "\n",
    "for key in ['ambiance', 'decor', 'atmosphere']:\n",
    "    print key.upper()\n",
    "    print pre[key], '\\n'\n",
    "    print post[key], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in ['experience', 'place', 'portions']:\n",
    "    print key.upper()\n",
    "    print pre[key], '\\n'\n",
    "    print post[key], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###General Notes\n",
    "- good, great, bad, worst, etc. map well to subjects that follow\n",
    "- joining \"over\" and \"reasonably\" to \"priced\" may create a nice feature\n",
    "- may be worth mapping \"high/low price\", \"high/low prices\" together\n",
    "- eliminate \"customer\" to better map the word \"service\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Subject mapping notes\n",
    "- \"server\", \"servers\", and \"service\" for service subject mappers\n",
    "- \"decor\", and \"ambiance\" for decor subject mappers\n",
    "- \"price(s)\" for price point mappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current order for extra preprocessing steps\n",
    "- join contractions\n",
    "- remove amplifier adverbs and \"customer\" (really, very, even, much, customer)\n",
    "- join sentiment flippers (not)\n",
    "- join \"priced\" (over, reasonably)\n",
    "- map generic adjectives to their following subjects (good, bad, worst, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try adjusting the processing steps after tokenizing the documents by removing adverbs from the list of words, then combining the word \"not\" to its following word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_path = 'yds/yelp_academic_dataset_review.json'\n",
    "original_data2 = get_data(d_path)\n",
    "train2, test2 = train_test_split(original_data2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered = ['really', 'very', 'even', 'much', 'real', 'customer', 'the', \\\n",
    "           'our', 'my', 'is', 'was']\n",
    "subjects = ['service', 'ambiance', 'portions', 'food', 'decor', 'price', \\\n",
    "           'restaurant', 'experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rev in train2:\n",
    "    text = rev['text'].lower()\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w not in filtered]\n",
    "    words = mapper(words)\n",
    "    words = join_fol(words, ['not'])\n",
    "    words = join_pre(words, ['priced'])\n",
    "    words = re_position(words)\n",
    "    words = join_pre(words, subjects)\n",
    "    words = [w for w in words if 'restaurant' not in w and 'experience' not in w]\n",
    "    rev['words'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rev in test2:\n",
    "    text = rev['text'].lower()\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w not in filtered]\n",
    "    words = mapper(words)\n",
    "    words = join_fol(words, ['not'])\n",
    "    words = join_pre(words, ['priced'])\n",
    "    words = re_position(words)\n",
    "    words = join_pre(words, subjects)\n",
    "    words = [w for w in words if 'restaurant' not in w and 'experience' not in w]\n",
    "    rev['words'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('algos/word_feats1.pickle', 'rb') as f:\n",
    "    word_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadf2 = pd.DataFrame(train2) \n",
    "X2 = datadf2[datadf2.stars != 3]\n",
    "y2 = X2.apply(lambda x: 1 if x.stars > 3 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for w in word_feats:\n",
    "    X2[w] = X2.apply(lambda x: 1 if w in x.words else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X2.drop(['words', 'categories', 'review_id', 'date', 'business_id', 'text', 'type', 'user_id', 'votes', 'stars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jachian/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.DataFrame(test2)\n",
    "X_test2 = testdf[testdf.stars != 3]\n",
    "y_test2 = X_test2.apply(lambda x: 1 if x.stars > 3 else 0, axis=1)\n",
    "for w in word_feats:\n",
    "    X_test2[w] = X_test2.apply(lambda x: 1 if w in x.words else 0, axis=1)\n",
    "X_test2.drop(['words', 'categories', 'review_id', 'date', 'business_id', 'text', 'type', 'user_id', 'votes', 'stars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = map_word_feats(train, test)\n",
    "with open('algos/word_feats1.pickle', 'rb') as f:\n",
    "    mapped_feats = pickle.load(f)\n",
    "X2, y2, X_test2, y_test2 = create_feature_matrix(train, test, mapped_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020928352061566"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X2, y2)\n",
    "rf.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('algos/RandomForestClassifier2.pickle', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_20 = np.argsort(rf.feature_importances_)[-1:-21:-1]\n",
    "X_test2.columns[top_20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(rf.feature_importances_)[-1:-21:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80352284631961346"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X2, y2)\n",
    "lr.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('algos/LogRegressionClassifier2.pickle', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_20 = np.argsort(lr.coef_[0])[-1:-21:-1]\n",
    "X_test2.columns[top_20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(lr.coef_[0])[-1:-21:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last bit of exploration with the word space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_w = [rev['words'] for rev in train2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('algos/word_feats1.pickle', 'rb') as f:\n",
    "    word_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre, post = exploratory_analysis(train_w, word_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove always (intensifier)\n",
    "# remove \"of\", map \"taste\" to \"food\"\n",
    "# leave \"mouth\" and \"flavors\" and \"enjoyed\"\n",
    "# maybe leave \"definitely\" and \"highly\"\n",
    "\n",
    "for w in ['definitely','highly','always','not always','enjoyed','mouth','taste','flavors']:\n",
    "    print w.upper()\n",
    "    print pre[w], '\\n'\n",
    "    print post[w], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- implement adverbs INCLUDING intensifiers\n",
    "- portions: \"the portions were __\", huge, large, small, generous, big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "horrible, regular, short, terrible, beautiful, entire, incredible, unique, wouldn't, awful, average, casual, interesting, fat, usual, delish, typical, avoid, standard, fair, exceptional\n",
    "- flavorful food\n",
    "- not flavorful food\n",
    "- helpful service\n",
    "- not helpful service\n",
    "- mean service\n",
    "- not mean service\n",
    "- generous portion\n",
    "- not generous portion\n",
    "- creamy food\n",
    "- not creamy food\n",
    "- crunchy food\n",
    "- not crunchy food\n",
    "- 'portions': 'portion'\n",
    "- 'cafe': 'restaurant'\n",
    "- expensive (investigate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print [w for w in temp if 'RB' in w[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print [w for w in temp if 'NN' in w[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set up pipeline for generating component scores for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('algos/weights.pickle', 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "with open('algos/food.pickle', 'rb') as f:\n",
    "    food = pickle.load(f)\n",
    "with open('algos/service.pickle', 'rb') as f:\n",
    "    service = pickle.load(f)\n",
    "with open('algos/atmosphere.pickle', 'rb') as f:\n",
    "    atmosphere = pickle.load(f)\n",
    "with open('algos/value.pickle', 'rb') as f:\n",
    "    value = pickle.load(f)\n",
    "with open('algos/decor.pickle', 'rb') as f:\n",
    "    decor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz_id = 'ydata/akikos-restaurant-san-francisco'\n",
    "with open(biz_id, 'r') as f:\n",
    "    temp = sj.load(f)['text']\n",
    "    biz_id = biz_id[6:]\n",
    "temp = [''.join(re.split(r'<br/>|\\n', doc)) for doc in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = ['really', 'very', 'even', 'much', 'real', 'customer', 'the', \\\n",
    "           'our', 'my', 'is', 'was']\n",
    "subjects = ['service', 'ambiance', 'portions', 'food', 'decor', 'price', \\\n",
    "           'restaurant', 'experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for rev in temp:\n",
    "    text = rev.lower().encode('ascii', 'ignore')\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w not in filtered]\n",
    "    words = mapper(words)\n",
    "    words = join_fol(words, ['not'])\n",
    "    words = join_pre(words, ['priced'])\n",
    "    words = re_position(words)\n",
    "    words = join_pre(words, subjects)\n",
    "    words = [w for w in words if 'restaurant' not in w and 'experience' not in w]\n",
    "    data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = temp\n",
    "df['words'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('algos/word_feats1.pickle', 'rb') as f:\n",
    "    word_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in word_feats:\n",
    "    df[w] = df.apply(lambda x: weights[w] if w in x.words else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['food'] = df[food].sum(axis=1)\n",
    "df['service'] = df[service].sum(axis=1)\n",
    "df['atmosphere'] = df[atmosphere].sum(axis=1)\n",
    "df['value'] = df[value].sum(axis=1)\n",
    "df['decor'] = df[decor].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akikos-restaurant-san-francisco\n",
      "0.668119402985\n",
      "0.0793233830846\n",
      "0.0391741293532\n",
      "-0.0385870646766\n",
      "-0.000338308457711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print biz_id\n",
    "for component in ['food', 'service', 'atmosphere', 'value', 'decor']:\n",
    "    print df[component].sum() / df.shape[0]\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cd ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hog-island-oyster-co-san-francisco', '4.6', '3.6', '3.3', '2.7', '3.0']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_weights('hog-island-oyster-co-san-francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akikos-restaurant-san-francisco', '5.0', '3.7', '3.9', '2.5', '3.0']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_weights('akikos-restaurant-san-francisco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Examine the Model by Making Searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Food and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('my_app/database/restaurants.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'delancey-street-restaurant-san-francisco', 4.1, 5.0),\n",
       " (u'front-door-cafe-san-francisco', 4.7, 4.4),\n",
       " (u'cafe-algiers-san-francisco', 4.3, 4.5),\n",
       " (u'chez-fayala-san-francisco', 4.8, 4.0),\n",
       " (u'dragoneats-san-francisco-3', 4.9, 3.9),\n",
       " (u'eatsa-san-francisco', 4.4, 4.4),\n",
       " (u'south-park-caf%C3%A9-san-francisco-4', 4.6, 3.7),\n",
       " (u'cafe-du-soleil-san-francisco-4', 5.0, 3.4),\n",
       " (u'la-fusi%C3%B3n-san-francisco-2', 4.8, 3.4),\n",
       " (u'barbacco-san-francisco', 4.6, 3.4),\n",
       " (u'eden-plaza-cafe-san-francisco', 4.4, 3.9),\n",
       " (u'crossroads-cafe-san-francisco-7', 3.9, 4.2),\n",
       " (u'fearless-coffee-san-francisco-3', 4.1, 3.9),\n",
       " (u'marlowe-san-francisco-2', 5.0, 2.9),\n",
       " (u'north-india-restaurant-san-francisco', 4.2, 3.4),\n",
       " (u'garaje-san-francisco', 4.5, 3.5),\n",
       " (u'sweet-joannas-cafe-san-francisco-2', 4.6, 3.5),\n",
       " (u'la-briciola-san-francisco', 4.5, 3.1),\n",
       " (u'portico-restaurant-san-francisco-3', 4.2, 3.9),\n",
       " (u'tropisue%C3%B1o-san-francisco-3', 4.5, 3.2)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALL = '''SELECT id, food, value FROM sf ORDER BY \n",
    "            food*? + service*? + atmosphere*? + value*? + decor*? DESC'''\n",
    "WEIGHTS = (5, 1, 1, 5, 1)\n",
    "cur.execute(CALL, WEIGHTS)\n",
    "cur.fetchmany(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Food, service, atmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'north-india-restaurant-san-francisco', 4.2, 5.0, 4.6),\n",
       " (u'la-briciola-san-francisco', 4.5, 4.7, 4.2),\n",
       " (u'crepe-madame-san-francisco-2', 4.5, 4.7, 4.0),\n",
       " (u'marlowe-san-francisco-2', 5.0, 4.1, 4.0),\n",
       " (u'per-diem-san-francisco', 4.3, 3.6, 5.0),\n",
       " (u'barbacco-san-francisco', 4.6, 3.9, 4.4),\n",
       " (u'hops-and-hominy-san-francisco', 4.4, 4.1, 4.6),\n",
       " (u'zero-zero-san-francisco', 4.9, 3.8, 4.3),\n",
       " (u'sauce-san-francisco-3', 4.3, 3.8, 4.8),\n",
       " (u'pachino-trattoria-and-pizzeria-san-francisco', 4.7, 4.1, 3.9),\n",
       " (u'south-park-caf%C3%A9-san-francisco-4', 4.6, 3.5, 4.3),\n",
       " (u'akikos-restaurant-san-francisco', 5.0, 3.7, 3.9),\n",
       " (u'la-fusi%C3%B3n-san-francisco-2', 4.8, 4.1, 3.5),\n",
       " (u'delancey-street-restaurant-san-francisco', 4.1, 4.5, 3.5),\n",
       " (u'tropisue%C3%B1o-san-francisco-3', 4.5, 3.7, 4.1),\n",
       " (u'trace-san-francisco', 4.4, 4.4, 3.6),\n",
       " (u'fearless-coffee-san-francisco-3', 4.1, 4.9, 3.0),\n",
       " (u'front-door-cafe-san-francisco', 4.7, 4.2, 3.0),\n",
       " (u'local-kitchen-and-wine-merchant-san-francisco-2', 4.3, 3.9, 4.0),\n",
       " (u'the-pink-elephant-san-francisco-3', 4.3, 3.4, 4.5)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALL = '''SELECT id, food, service, atmosphere FROM sf ORDER BY \n",
    "            food*? + service*? + atmosphere*? + value*? + decor*? DESC'''\n",
    "WEIGHTS = (5, 5, 5, 1, 1)\n",
    "cur.execute(CALL, WEIGHTS)\n",
    "cur.fetchmany(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decor and atmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'per-diem-san-francisco', 5.0, 3.8),\n",
       " (u'burritt-room-tavern-san-francisco', 4.8, 3.3),\n",
       " (u'sauce-san-francisco-3', 4.8, 3.0),\n",
       " (u'barbacco-san-francisco', 4.4, 3.0),\n",
       " (u'hops-and-hominy-san-francisco', 4.6, 3.0),\n",
       " (u'the-grove-yerba-buena-san-francisco', 4.6, 3.3),\n",
       " (u'north-india-restaurant-san-francisco', 4.6, 2.6),\n",
       " (u'la-capra-san-francisco-2', 4.3, 3.3),\n",
       " (u'south-park-caf%C3%A9-san-francisco-4', 4.3, 3.0),\n",
       " (u'trou-normand-san-francisco', 4.2, 3.5),\n",
       " (u'zero-zero-san-francisco', 4.3, 3.0),\n",
       " (u'la-briciola-san-francisco', 4.2, 2.9),\n",
       " (u'the-pink-elephant-san-francisco-3', 4.5, 3.0),\n",
       " (u'crepe-madame-san-francisco-2', 4.0, 3.0),\n",
       " (u'marlowe-san-francisco-2', 4.0, 3.0),\n",
       " (u'osha-thai-san-francisco', 4.4, 3.0),\n",
       " (u'tropisue%C3%B1o-san-francisco-3', 4.1, 3.0),\n",
       " (u'samovar-tea-lounge-san-francisco-2', 4.2, 3.3),\n",
       " (u'archive-bar-and-kitchen-san-francisco', 4.1, 3.0),\n",
       " (u'jersey-san-francisco', 3.0, 4.0)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALL = '''SELECT id, atmosphere, decor FROM sf ORDER BY \n",
    "            food*? + service*? + atmosphere*? + value*? + decor*? DESC'''\n",
    "WEIGHTS = (1, 1, 5, 1, 5)\n",
    "cur.execute(CALL, WEIGHTS)\n",
    "cur.fetchmany(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fooooooood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'marlowe-san-francisco-2', 5.0),\n",
       " (u'cafe-du-soleil-san-francisco-4', 5.0),\n",
       " (u'zero-zero-san-francisco', 4.9),\n",
       " (u'akikos-restaurant-san-francisco', 5.0),\n",
       " (u'front-door-cafe-san-francisco', 4.7),\n",
       " (u'la-fusi%C3%B3n-san-francisco-2', 4.8),\n",
       " (u'barbacco-san-francisco', 4.6),\n",
       " (u'dragoneats-san-francisco-3', 4.9),\n",
       " (u'south-park-caf%C3%A9-san-francisco-4', 4.6),\n",
       " (u'la-briciola-san-francisco', 4.5),\n",
       " (u'chez-fayala-san-francisco', 4.8),\n",
       " (u'crepe-madame-san-francisco-2', 4.5),\n",
       " (u'pachino-trattoria-and-pizzeria-san-francisco', 4.7),\n",
       " (u'per-diem-san-francisco', 4.3),\n",
       " (u'freshroll-vietnamese-rolls-and-bowls-san-francisco', 4.9),\n",
       " (u'north-india-restaurant-san-francisco', 4.2),\n",
       " (u'tropisue%C3%B1o-san-francisco-3', 4.5),\n",
       " (u'delancey-street-restaurant-san-francisco', 4.1),\n",
       " (u'wanna-e-san-francisco', 4.6),\n",
       " (u'super-duper-burgers-san-francisco-3', 4.7)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALL = '''SELECT id, food FROM sf ORDER BY \n",
    "            food*? + service*? + atmosphere*? + value*? + decor*? DESC'''\n",
    "WEIGHTS = (5, 1, 1, 1, 1)\n",
    "cur.execute(CALL, WEIGHTS)\n",
    "cur.fetchmany(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'delancey-street-restaurant-san-francisco', 4.1, 4.5, 3.5, 5.0, 2.8),\n",
       " (u'north-india-restaurant-san-francisco', 4.2, 5.0, 4.6, 3.4, 2.6),\n",
       " (u'per-diem-san-francisco', 4.3, 3.6, 5.0, 2.9, 3.8),\n",
       " (u'la-briciola-san-francisco', 4.5, 4.7, 4.2, 3.1, 2.9),\n",
       " (u'barbacco-san-francisco', 4.6, 3.9, 4.4, 3.4, 3.0),\n",
       " (u'front-door-cafe-san-francisco', 4.7, 4.2, 3.0, 4.4, 3.0),\n",
       " (u'crepe-madame-san-francisco-2', 4.5, 4.7, 4.0, 3.0, 3.0),\n",
       " (u'south-park-caf%C3%A9-san-francisco-4', 4.6, 3.5, 4.3, 3.7, 3.0),\n",
       " (u'marlowe-san-francisco-2', 5.0, 4.1, 4.0, 2.9, 3.0),\n",
       " (u'fearless-coffee-san-francisco-3', 4.1, 4.9, 3.0, 3.9, 3.0),\n",
       " (u'la-fusi%C3%B3n-san-francisco-2', 4.8, 4.1, 3.5, 3.4, 3.0),\n",
       " (u'sauce-san-francisco-3', 4.3, 3.8, 4.8, 2.8, 3.0),\n",
       " (u'zero-zero-san-francisco', 4.9, 3.8, 4.3, 2.7, 3.0),\n",
       " (u'cafe-du-soleil-san-francisco-4', 5.0, 3.8, 3.0, 3.4, 3.3),\n",
       " (u'crossroads-cafe-san-francisco-7', 3.9, 3.5, 3.9, 4.2, 3.0),\n",
       " (u'hops-and-hominy-san-francisco', 4.4, 4.1, 4.6, 2.4, 3.0),\n",
       " (u'tropisue%C3%B1o-san-francisco-3', 4.5, 3.7, 4.1, 3.2, 3.0),\n",
       " (u'jersey-san-francisco', 4.4, 4.1, 3.0, 2.8, 4.0),\n",
       " (u'pachino-trattoria-and-pizzeria-san-francisco', 4.7, 4.1, 3.9, 2.5, 3.0),\n",
       " (u'akikos-restaurant-san-francisco', 5.0, 3.7, 3.9, 2.5, 3.0)]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALL = '''SELECT * FROM sf ORDER BY \n",
    "            food*? + service*? + atmosphere*? + value*? + decor*? DESC'''\n",
    "WEIGHTS = (5, 5, 5, 5, 5)\n",
    "cur.execute(CALL, WEIGHTS)\n",
    "cur.fetchmany(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'delancey-street-restaurant-san-francisco', 4.1, 4.5, 3.5, 5.0, 2.8),\n",
       " (u'north-india-restaurant-san-francisco', 4.2, 5.0, 4.6, 3.4, 2.6),\n",
       " (u'front-door-cafe-san-francisco', 4.7, 4.2, 3.0, 4.4, 3.0),\n",
       " (u'la-briciola-san-francisco', 4.5, 4.7, 4.2, 3.1, 2.9),\n",
       " (u'crepe-madame-san-francisco-2', 4.5, 4.7, 4.0, 3.0, 3.0),\n",
       " (u'marlowe-san-francisco-2', 5.0, 4.1, 4.0, 2.9, 3.0),\n",
       " (u'fearless-coffee-san-francisco-3', 4.1, 4.9, 3.0, 3.9, 3.0),\n",
       " (u'barbacco-san-francisco', 4.6, 3.9, 4.4, 3.4, 3.0),\n",
       " (u'la-fusi%C3%B3n-san-francisco-2', 4.8, 4.1, 3.5, 3.4, 3.0),\n",
       " (u'cafe-du-soleil-san-francisco-4', 5.0, 3.8, 3.0, 3.4, 3.3),\n",
       " (u'south-park-caf%C3%A9-san-francisco-4', 4.6, 3.5, 4.3, 3.7, 3.0),\n",
       " (u'zero-zero-san-francisco', 4.9, 3.8, 4.3, 2.7, 3.0),\n",
       " (u'per-diem-san-francisco', 4.3, 3.6, 5.0, 2.9, 3.8),\n",
       " (u'wanna-e-san-francisco', 4.6, 4.3, 3.0, 3.0, 3.0),\n",
       " (u'pachino-trattoria-and-pizzeria-san-francisco', 4.7, 4.1, 3.9, 2.5, 3.0),\n",
       " (u'tropisue%C3%B1o-san-francisco-3', 4.5, 3.7, 4.1, 3.2, 3.0),\n",
       " (u'akikos-restaurant-san-francisco', 5.0, 3.7, 3.9, 2.5, 3.0),\n",
       " (u'dragoneats-san-francisco-3', 4.9, 3.2, 3.0, 3.9, 3.0),\n",
       " (u'eden-plaza-cafe-san-francisco', 4.4, 3.8, 3.0, 3.9, 3.0),\n",
       " (u'chez-fayala-san-francisco', 4.8, 3.2, 3.0, 4.0, 3.0)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALL = '''SELECT * FROM sf ORDER BY \n",
    "            food*? + service*? + atmosphere*? + value*? + decor*? DESC'''\n",
    "WEIGHTS = (5, 4, 2, 3, 1)\n",
    "cur.execute(CALL, WEIGHTS)\n",
    "cur.fetchmany(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "['hog-island-oyster-co-san-francisco', '4.6', '3.6', '3.3', '2.7', '3.0']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "components = ['food', 'service', 'atmosphere', 'value', 'decor']\n",
    "x_pos = np.arange(len(components))\n",
    "scores = [4.6, 3.6, 3.3, 2.7, 3.0]\n",
    "\n",
    "bars = plt.bar(x_pos, scores, width=0.5, alpha=0.9)\n",
    "plt.xticks(x_pos, components, fontsize=16, rotation=45)\n",
    "bars[0].set_color('#c41200')\n",
    "bars[1].set_color('#e64518')\n",
    "bars[2].set_color('#e64518')\n",
    "bars[3].set_color('#e39f59')\n",
    "bars[4].set_color('#e64518')\n",
    "plt.title('Hog Island Oyster Co', fontsize=18)\n",
    "ylim(ymax=5)\n",
    "ax.grid(False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
